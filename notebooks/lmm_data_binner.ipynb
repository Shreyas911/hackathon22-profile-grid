{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e30c2579-77dd-4f9d-b536-b48dc78bfa5d",
   "metadata": {},
   "source": [
    "# Bin data on time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09da89ef-80ec-489a-8cca-4c325798ac7d",
   "metadata": {},
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "49e8297f-8c91-4f4b-9e35-eace1c18df0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import math\n",
    "from operator import itemgetter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2dd68bc-32eb-4dbd-90ba-a71411d215cf",
   "metadata": {},
   "source": [
    "## Convert dataframe to xarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "09539c7f-7bb0-4d36-9996-5e5250bc2e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://notebook.community/jhamman/xarray/examples/xarray_multidimensional_coords\n",
    "\n",
    "class DataBinner:\n",
    "    \n",
    "    def __init__(self, df, pressure_range, pressure_bin_size):\n",
    "        \n",
    "        self.df = df\n",
    "        self.pressure_range = pressure_range\n",
    "        self.pressure_bin_size = pressure_bin_size\n",
    "                \n",
    "            \n",
    "    def get_coords(self):\n",
    "        \n",
    "        return ('pres', 'profile_id', 'cycle_number', 'lat', 'lon', 'date', 'year', 'month', 'day')\n",
    "\n",
    "#     def set_df_index(self):\n",
    "#         self.df_indexed = self.df.set_index(['cycle_number', 'lat', 'lon', 'datetime', 'year', 'month', 'day', 'pres'])\n",
    "    \n",
    "    \n",
    "#     def index_on_profile_id(self):\n",
    "#         self.df = self.df.set_index(['profile_id'])\n",
    "        \n",
    "        \n",
    "#     def get_df_grouped_by_id(self):\n",
    "        \n",
    "#         # https://stackoverflow.com/questions/22219004/how-to-group-dataframe-rows-into-list-in-pandas-groupby\n",
    "        \n",
    "#         self.index_on_profile_id()\n",
    "        \n",
    "#         df = self.df\n",
    "        \n",
    "#         # Create a datetime column\n",
    "#         self.df['datetime'] = pd.to_datetime(self.df['date'])\n",
    "\n",
    "#         def f_multi(df,col_names):\n",
    "#             if not isinstance(col_names,list):\n",
    "#                 col_names = [col_names]\n",
    "\n",
    "#             values = df.sort_values(col_names).values.T\n",
    "\n",
    "#             col_idcs = [df.columns.get_loc(cn) for cn in col_names]\n",
    "#             other_col_names = [name for idx, name in enumerate(df.columns) if idx not in col_idcs]\n",
    "#             other_col_idcs = [df.columns.get_loc(cn) for cn in other_col_names]\n",
    "\n",
    "#             # split df into indexing colums(=keys) and data colums(=vals)\n",
    "#             keys = values[col_idcs,:]\n",
    "#             vals = values[other_col_idcs,:]\n",
    "\n",
    "#             # list of tuple of key pairs\n",
    "#             multikeys = list(zip(*keys))\n",
    "\n",
    "#             # remember unique key pairs and ther indices\n",
    "#             ukeys, index = np.unique(multikeys, return_index=True, axis=0)\n",
    "\n",
    "#             # split data columns according to those indices\n",
    "#             arrays = np.split(vals, index[1:], axis=1)\n",
    "\n",
    "#             # resulting list of subarrays has same number of subarrays as unique key pairs\n",
    "#             # each subarray has the following shape:\n",
    "#             #    rows = number of non-grouped data columns\n",
    "#             #    cols = number of data points grouped into that unique key pair\n",
    "\n",
    "#             # prepare multi index\n",
    "#             idx = pd.MultiIndex.from_arrays(ukeys.T, names=col_names) \n",
    "\n",
    "#             list_agg_vals = dict()\n",
    "#             for tup in zip(*arrays, other_col_names):\n",
    "#                 col_vals = tup[:-1] # first entries are the subarrays from above \n",
    "#                 col_name = tup[-1]  # last entry is data-column name\n",
    "\n",
    "#                 list_agg_vals[col_name] = col_vals\n",
    "\n",
    "#             df2 = pd.DataFrame(data=list_agg_vals, index=idx)\n",
    "#             return df2\n",
    "\n",
    "\n",
    "#         df_group = f_multi(df, ['date'])\n",
    "        \n",
    "#         return df_group\n",
    "    \n",
    "#     def create_dataframe(self, df):\n",
    "        \n",
    "#         #df = df_group.to_frame()\n",
    "\n",
    "#         # There is only one elem and it's a list because only one col header (the date)\n",
    "\n",
    "#         column_name = df.columns[0]\n",
    "\n",
    "#         # expand column into its own dataframe\n",
    "#         exploded = df[column_name].apply(pd.Series)\n",
    "\n",
    "#         # rename each variable \n",
    "#         exploded = exploded.rename(columns = lambda x : 'tag_' + str(x))\n",
    "\n",
    "#         # transpose the df and remove index column\n",
    "#         df = exploded.T\n",
    "\n",
    "#         self.df = df.reset_index(drop=True)\n",
    "        \n",
    "#         return self.df\n",
    "    \n",
    "    \n",
    "    def apply_qc(self, ds):\n",
    "        \n",
    "        # TODO\n",
    "        # Use qc here to filter things\n",
    "\n",
    "        # For now, I'm just going to drop the qc columns\n",
    "        \n",
    "        try:\n",
    "            ds = ds.drop('pres_qc')\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        try:\n",
    "            ds = ds.drop(('psal_qc', 'temp_qc'))\n",
    "        except:\n",
    "            pass  \n",
    "\n",
    "        return ds\n",
    "\n",
    "    def create_mean_ds(self, ds_grouped):\n",
    "\n",
    "        ds_list = []\n",
    "\n",
    "        binned_pres = []\n",
    "        temp = []\n",
    "        psal = []\n",
    "        meta = []\n",
    "\n",
    "        for name, group in ds_grouped:\n",
    "\n",
    "            metadata = {}\n",
    "\n",
    "            temp_mean = group['temp'].mean().data\n",
    "            psal_mean = group['psal'].mean().data\n",
    "\n",
    "            # The name is the pressure bin label (numeric)\n",
    "            binned_pres.append(name)\n",
    "            temp.append(temp_mean.item())\n",
    "            psal.append(psal_mean.item())\n",
    "\n",
    "\n",
    "            for name in group.coords:\n",
    "\n",
    "                if name == 'index' or name =='pres':\n",
    "                    continue\n",
    "\n",
    "                val = group[name][0].values.item()\n",
    "\n",
    "                metadata[name] = val\n",
    "\n",
    "            meta.append(metadata)\n",
    "\n",
    "            # {'cycle_number': 17.0, 'profile_id': '3902235_17', 'lat': -14.35528, \n",
    "            # 'lon': -33.87904, 'date': '2020-01-30T22:17:05.002Z', 'year': 2020, 'month': 1, 'day': 30}\n",
    "\n",
    "\n",
    "\n",
    "        # list of dicts, extract each key into list\n",
    "        \n",
    "        # Get values of particular key in list of dictionaries\n",
    "        all_lat = list(map(itemgetter('lat'), meta))\n",
    "\n",
    "        meta_names = list(meta[0].keys())\n",
    "\n",
    "        all_elems = {}\n",
    "        for name in meta_names:\n",
    "\n",
    "            all_elems[name] = list(map(itemgetter(name), meta))\n",
    "\n",
    "\n",
    "        da_all = {}\n",
    "\n",
    "        for key,val in all_elems.items():\n",
    "\n",
    "            da_all[key] = xr.DataArray(\n",
    "                        data   = val,\n",
    "                        dims   = ['pres'],\n",
    "                        coords = {'pres': binned_pres}\n",
    "                        )  \n",
    "\n",
    "        da_temp = xr.DataArray(\n",
    "                    data   = temp,\n",
    "                    dims   = ['pres'],\n",
    "                    coords = {'pres': binned_pres}\n",
    "                    )\n",
    "\n",
    "        da_psal = xr.DataArray(\n",
    "                    data   = psal,\n",
    "                    dims   = ['pres'],\n",
    "                    coords = {'pres': binned_pres}\n",
    "                    )\n",
    "\n",
    "        da_shape = da_psal.shape\n",
    "\n",
    "        ds_new = xr.Dataset({\n",
    "            'temp': da_temp,\n",
    "            'psal': da_psal})\n",
    "\n",
    "\n",
    "        for name in meta_names:\n",
    "\n",
    "            ds_new[name] = da_all[name]\n",
    "\n",
    "        coords = self.get_coords()\n",
    "            \n",
    "        ds_new = ds_new.set_coords(coords)\n",
    "\n",
    "        return ds_new\n",
    "\n",
    "\n",
    "\n",
    "    def bin_on_pressure(self, ds_all_profile_groups):\n",
    "        \n",
    "        min_pres = self.pressure_range[0]\n",
    "        max_pres = self.pressure_range[1]\n",
    "        \n",
    "        bin_size = self.pressure_bin_size\n",
    "        \n",
    "        ds_mean_list = []\n",
    "\n",
    "        for name, profile_group in ds_all_profile_groups:\n",
    "            \n",
    "            pres_bins = np.arange(min_pres, max_pres, bin_size)\n",
    "\n",
    "            # define a label for each bin corresponding to the centreal pressure\n",
    "            pres_center = np.arange(min_pres + bin_size/2, max_pres - bin_size/2, bin_size)\n",
    "\n",
    "            # group according to those bins and take the mean\n",
    "            ds_grouped_pres = profile_group.groupby_bins('pres', pres_bins, labels=pres_center)\n",
    "\n",
    "            ds_mean = self.create_mean_ds(ds_grouped_pres)\n",
    "\n",
    "            ds_mean_list.append(ds_mean)\n",
    "            \n",
    "        ds_all = xr.concat(ds_mean_list, dim ='pres')\n",
    "        \n",
    "        return ds_all\n",
    "        \n",
    "    \n",
    "    def create_xarray(self):\n",
    "        \n",
    "        # Create a datetime column\n",
    "        # self.df['datetime'] = pd.to_datetime(self.df['date'])\n",
    "        \n",
    "        # Create a unique column of profile_id + date\n",
    "        \n",
    "        ds = df.to_xarray()\n",
    "        \n",
    "        # print(ds)\n",
    "        # print(list(ds.coords))\n",
    "        # print(list(ds.keys()))\n",
    "        \n",
    "        profile_id = ds['profile_id'].data\n",
    "        \n",
    "        date = ds['date'].data\n",
    "\n",
    "        unique_col = np.array(list(map('_'.join, zip(profile_id, date))))\n",
    "\n",
    "        ds[\"unique_id\"]=(['index'],  unique_col)\n",
    "                \n",
    "        coords = self.get_coords()\n",
    "        \n",
    "        ds = ds.set_coords(coords)\n",
    "        \n",
    "        ds = ds.set_coords('unique_id')\n",
    "                        \n",
    "        ds = self.apply_qc(ds)\n",
    "        \n",
    "        ds_all_profile_groups = ds.groupby('unique_id')\n",
    "        \n",
    "        #ds_all_profile_groups = ds.groupby('profile_id')\n",
    "        \n",
    "        ds_all = self.bin_on_pressure(ds_all_profile_groups)\n",
    "        \n",
    "        \n",
    "        return ds_all\n",
    "    \n",
    "    \n",
    "    def get_datetime_bounds(self):\n",
    "        \n",
    "        min_time = self.df['datetime'].min()\n",
    "        max_time = self.df['datetime'].max()\n",
    "        \n",
    "        return min_time, max_time\n",
    "    \n",
    "    def bin_on_time(self, ds_all, interval):\n",
    "        \n",
    "        if interval == 'day':\n",
    "        \n",
    "            bins = np.arange(0,31)\n",
    "\n",
    "            bin_center = np.arange(.5,30.5)\n",
    "\n",
    "            # group according to those bins and take the mean\n",
    "            ds_all_grouped = ds_all.groupby_bins('day', bins, labels=bin_center)\n",
    "            \n",
    "        elif interval == 'month':\n",
    "            \n",
    "            bins = np.arange(1,13)\n",
    "\n",
    "            # define a label for each bin corresponding to the central value\n",
    "            bin_center = np.arange(1.5,12.5)\n",
    "\n",
    "            # group according to those bins and take the mean\n",
    "            ds_all_grouped = ds_all.groupby_bins('month', bins, labels=bin_center)         \n",
    "        \n",
    "        return ds_all_grouped\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b78ad15b-f15e-4a21-b4df-fff2d39d93a7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
