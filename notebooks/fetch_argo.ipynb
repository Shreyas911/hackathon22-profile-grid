{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data processing\n",
    "import requests, copy, math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.interpolate\n",
    "\n",
    "#data visualization\n",
    "import matplotlib.pylab as plt\n",
    "from matplotlib import ticker\n",
    "\n",
    "#used for map projections\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cft\n",
    "from cartopy.mpl.gridliner import LONGITUDE_FORMATTER, LATITUDE_FORMATTER\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# To see what this polygon looks like, visit https://argovis.colorado.edu/ng/home?mapProj=WM&presRange=%5B0,2000%5D&selectionStartDate=2022-03-31T22:30:45Z&selectionEndDate=2022-04-14T22:30:45Z&threeDayEndDate=2022-04-12T22:30:45&shapes=%5B%5B%5B22.105999,-76.289063%5D,%5B26.902477,-72.597656%5D,%5B26.084682,-66.395555%5D,%5B25.005973,-60.292969%5D,%5B10.833306,-65.566406%5D,%5B11.942098,-72.133142%5D,%5B22.105999,-76.289063%5D%5D%5D&includeRealtime=true&onlyBGC=false&onlyDeep=false&threeDayToggle=false\n",
    "def check_error_message(ans,writeFlag=False):\n",
    "    # ans: response JSON from an API query\n",
    "    # writeFlag: bool, true == print verbose errors, if found\n",
    "    # returns error code if found, or NaN if not.\n",
    "    if isinstance(ans,dict) and 'message' in ans.keys() and 'code' in ans.keys():\n",
    "        if writeFlag:\n",
    "            print(str(ans['code']) + ': ' + ans['message'])\n",
    "        ##### NOTE: we should include here below all the codes that do not return data as the user expects\n",
    "        if ans['code'] >= 400 and ans['code'] != 404:\n",
    "            print('Data were not returned')\n",
    "            print(ans)\n",
    "            raise Exception('No data')\n",
    "        return ans['code']        \n",
    "    elif ans:\n",
    "        return np.nan\n",
    "#####\n",
    "# check if the object is a list of dictionaries\n",
    "def check_list_of_dict(lst,writeFlag=False):\n",
    "    # lst: object to check if is a list of dicts\n",
    "    # writeFlag: bool, true == verbose mode\n",
    "    # return 1 if lst is a list of dicts, 0 ow\n",
    "    if lst and isinstance(lst,list):\n",
    "        if all(isinstance(i, dict) for i in lst):\n",
    "            if writeFlag:\n",
    "                print('Number of items: '+str(len(lst)))\n",
    "            return 1\n",
    "        else:\n",
    "            if writeFlag:\n",
    "                print(lst) \n",
    "            return 0\n",
    "    else:\n",
    "        if writeFlag:\n",
    "            print(lst) \n",
    "        return 0 \n",
    "######\n",
    "def get_data_from_url(url,myAPIkey,writeFlag=False):\n",
    "    # url: string url to attempt to query\n",
    "    # myAPIkey: string API key, get yours at https://argovis-apikey-manager-atoc-argovis-dev.apps.containers02.colorado.edu/ \n",
    "    # myAPIkey can also be left empty '', yet in this case the user is more likely to exceed API request limits (and get HTTP 403 errors).\n",
    "    # returns a dictionary representation of the reponse from the endpoint hit in url; empty list if 404.\n",
    "    try:\n",
    "        d_raw = requests.get(url,headers={\"x-argokey\": myAPIkey}).json()\n",
    "        ans = check_error_message(ans=d_raw,writeFlag=writeFlag)\n",
    "    except:\n",
    "        print(url)\n",
    "        raise Exception('No data')\n",
    "    # check that data are a list of dictionaries as expected\n",
    "    if ans == 404:\n",
    "        return []\n",
    "    elif np.isnan(ans) and check_list_of_dict(lst=d_raw,writeFlag=writeFlag) == 1:\n",
    "        if writeFlag:\n",
    "            print(url)\n",
    "        return d_raw\n",
    "    else:\n",
    "        print(ans)\n",
    "        raise Exception('Check object type and error code')\n",
    "#####\n",
    "def create_url(url_prefix, \\\n",
    "               startDate='',endDate='', \\\n",
    "               radius_km=[],center=[], \\\n",
    "               polygon=[],data='',presRange='', \\\n",
    "               source='',platform_id='',woceline='',profile_id=''):\n",
    "    # url_prefix: string root of API routes\n",
    "    # startDate [endDate]: string start [end] date to filter documents on, in ISO 8601 UTC datestrings ie 1999-12-31T00:00:00Z\n",
    "    # radius_km: float distance to search in proximity search; must be passed with center\n",
    "    # center: [lon, lat] list of center of proximity search; must be passed with radius_km\n",
    "    # polygon: [[lon0, lat0], [lon1, lat1], ... [lon0, lat0]] list of lists of lon/lat pairs describing polygon bounding box for region search; first coord must == last coord\n",
    "    # data: comma delimited string of data variables to seatch for ANDed together, ie 'pres,temp,doxy'. Admits negation ('pres,temp,~doxy'); will return the actual measurements listed and filter for profiles that have them. Get metadata only by including 'metadata-only'.\n",
    "    # presRange: comma delimited string indicating min and max pressure to return levels for, ie '0,100' for top 100 dbar\n",
    "    # source: comma delimited string of data sources, ANDed together, such as 'argo_core' or 'cchdo_go-ship'. Accepts negation, ie 'argo_core,~argo_bgc'\n",
    "    # platform_id: string indicating ID of Argo platform to search for\n",
    "    # woceline: string indicating WOCE line to search for\n",
    "    # profile_id: string indicating profile ID to search for\n",
    "    # returns: string URL for performing the desired search (note all filters are ANDed together).\n",
    "\n",
    "    url = url_prefix\n",
    "    \n",
    "    if startDate:\n",
    "        url = url + '&startDate=' + startDate\n",
    "    if endDate:\n",
    "        url = url + '&endDate=' + endDate\n",
    "        \n",
    "    # regional queries\n",
    "    if radius_km and center:\n",
    "        url = url + '&radius=' + radius_km + '&center=' + center\n",
    "    elif polygon:\n",
    "        url = url + '&polygon=' + polygon\n",
    "        \n",
    "    # queries by variable data\n",
    "    if data:\n",
    "        url = url + '&data=' + data\n",
    "    \n",
    "    # queries by pressure range\n",
    "    if presRange:\n",
    "        url = url + '&presRange=' + presRange\n",
    "    \n",
    "    # queries by source\n",
    "    if source:\n",
    "        url = url + '&source=' + source\n",
    "    \n",
    "    # queries by platform id\n",
    "    if platform_id:\n",
    "        url = url + '&platform_id=' + platform_id\n",
    "    \n",
    "    # queries by woceline\n",
    "    if woceline:\n",
    "        url = url + '&woceline=' + woceline\n",
    "\n",
    "    # queries by _id\n",
    "    if profile_id:\n",
    "        url = url + '&id=' + profile_id\n",
    "        \n",
    "    return url\n",
    "#####\n",
    "def get_data_for_timeRange(startDate,endDate,url_prefix, \\\n",
    "                     myAPIkey,\\\n",
    "                     radius_km=[],center=[], \\\n",
    "                     polygon=[],data='',presRange='', \\\n",
    "                     source='',platform_id='',woceline='', \\\n",
    "                     dt_tag='d',writeFlag=False):\n",
    "    # all inputs as create_url, excpet:\n",
    "    # myAPIkey: string API key for Argovis API\n",
    "    # dt_tag: frequency tag as defined at https://pandas.pydata.org/docs/user_guide/timeseries.html#timeseries-offset-aliases; \n",
    "    # determines how much data is downloaded per request (we suggest 'd' to avoid requesting too much data all at once; it should be tuned based e.g. \n",
    "    # on the size of the region of interest)\n",
    "    # returns a dataframe describing the data returned by the specified query string filters\n",
    "\n",
    "    list_of_days = create_list_of_days(startDate,endDate,dt_tag=dt_tag)\n",
    "    info_ALL = []\n",
    "    for i in np.arange(0,len(list_of_days)-1):\n",
    "        url_to_use = create_url(url_prefix=url_prefix, \\\n",
    "                               startDate=list_of_days[i], \\\n",
    "                               endDate=list_of_days[i+1], \\\n",
    "                               radius_km=radius_km,center=center, \\\n",
    "                               polygon=polygon,data=data,presRange=presRange, \\\n",
    "                               source=source,platform_id=platform_id,woceline=woceline)\n",
    "        #print(url_to_use)\n",
    "        info_ALL   = info_ALL + get_data_from_url(url=url_to_use,myAPIkey=myAPIkey,writeFlag=writeFlag)\n",
    "                               \n",
    "    info_ALL = pd.DataFrame(info_ALL)\n",
    "    \n",
    "    return info_ALL\n",
    "\n",
    "def create_list_of_days(startDate,endDate,dt_tag='d'): \n",
    "    # dt_tag could be '30T', 'd', ...\n",
    "    list_of_days = (pd.DataFrame(columns=['NULL'],\n",
    "                            index=pd.date_range(startDate,endDate,\n",
    "                                                freq=dt_tag)) #'d'\n",
    "                                   .between_time('00:00','23:59')\n",
    "                                   .index.strftime('%Y-%m-%dT%H:%M:%SZ')\n",
    "                                   .tolist()\n",
    "                )\n",
    "    if list_of_days[-1] != endDate:\n",
    "        list_of_days.append(endDate[0:11]+'23:59:59Z')\n",
    "    return list_of_days\n",
    "\n",
    "def get_info_from_df(df,info_to_store):\n",
    "    # df: dataframe as returned by ie get_data_for_timeRange\n",
    "    # info_to_store: list of strings indicating variables of interest\n",
    "    # returns dictionary packing of listed info from dataframe\n",
    "\n",
    "    if isinstance(df,pd.DataFrame):\n",
    "        lon  = []\n",
    "        lat  = []\n",
    "        date = []\n",
    "        cols_bySource=[]\n",
    "        ids  = []\n",
    "        woce_line = []\n",
    "        \n",
    "        lst_out = []\n",
    "        \n",
    "        for i in np.arange(0,len(df),1):\n",
    "            #\n",
    "            if any(\"lon\" in s for s in info_to_store) or  any(\"lat\" in s for s in info_to_store):\n",
    "                lon.append(df.geolocation[i]['coordinates'][0])\n",
    "                lat.append(df.geolocation[i]['coordinates'][1])\n",
    "            #\n",
    "            if any(\"date\" in s for s in info_to_store):\n",
    "                date.append(df.timestamp[i][0:-5]+'Z')\n",
    "            #\n",
    "            if any(\"ids\" in s for s in info_to_store):\n",
    "                ids.append(df._id[i])\n",
    "            #\n",
    "            if any(\"cols_bySource\" in s for s in info_to_store):\n",
    "                bfr_source= []\n",
    "                for jsource in df.source_info[i]:\n",
    "                    bfr_source = bfr_source + jsource['source']\n",
    "                cols_bySource.append('y')\n",
    "            # \n",
    "            if any(\"woce_line\" in s for s in info_to_store):\n",
    "                if \"woce_line\" in df.keys():\n",
    "                    woce_line.append(df.woce_line[i])\n",
    "                    \n",
    "        for i in info_to_store:\n",
    "            if len(eval(i)) ==len(df) or not eval(i):\n",
    "                eval('lst_out.append('+ i +')')\n",
    "            else:\n",
    "                raise Exception('check length')\n",
    "            \n",
    "        dict_info = {}\n",
    "        for i,ival in zip(info_to_store,lst_out):\n",
    "            if ival:\n",
    "                dict_info[i] = ival\n",
    "    return dict_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_lon_lat(df):\n",
    "    \n",
    "    def get_lon_lat(cell):\n",
    "\n",
    "        return cell['coordinates']\n",
    "\n",
    "    df['lon_lat'] = df['geolocation'].apply(get_lon_lat)\n",
    "\n",
    "    df_lon_lat = pd.DataFrame(df['lon_lat'].to_list(), columns=['lon', 'lat'])\n",
    "    \n",
    "    df['lon'] = df_lon_lat['lon']\n",
    "    df['lat'] = df_lon_lat['lat']\n",
    "    \n",
    "    df = df.drop(columns=['geolocation', 'lon_lat'])\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_source_info(df):\n",
    "    \n",
    "    def get_source(cell):\n",
    "        \n",
    "        source = cell[0]['source']\n",
    "        source_str = ','.join(source)\n",
    "\n",
    "        return source_str\n",
    "    \n",
    "    df['source'] = df['source_info'].apply(get_source)\n",
    "    \n",
    "    df = df.drop(columns=['source_info'])\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lmm_parse_df(df):\n",
    "    \n",
    "    columns = list(df.columns)\n",
    "    \n",
    "    rows = df.shape[0]\n",
    "    master = pd.DataFrame()\n",
    "    \n",
    "    for i in range(rows):\n",
    "        \n",
    "        profile = pd.DataFrame( df.iloc[i]['data'])\n",
    "        \n",
    "        #profile['profile_id'] = df.iloc[i]['_id']\n",
    "        \n",
    "        for name in columns:\n",
    "            \n",
    "            if name == 'data':\n",
    "                continue\n",
    "            \n",
    "            if name == 'source':\n",
    "                continue\n",
    "                \n",
    "            try:\n",
    "                profile[name] = df.iloc[i][name]\n",
    "            except:\n",
    "                print(f\"error with {name}\")\n",
    "                \n",
    "        master = pd.concat([master, profile])\n",
    "        \n",
    "    master['source'] = df['source']\n",
    "    \n",
    "    master = master.rename(columns={'_id': 'profile_id'})\n",
    "        \n",
    "    return master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #cell to change\n",
    "\n",
    "# atlantic_coords = [[-40.078125,29.840644],[-33.368671,30.338837],[-26.614528,30.492027],\n",
    "#                     [-19.863281,30.297018],[-20.039063,-30.145127],[-26.724822,-30.384017],\n",
    "#                     [-33.419918,-30.281826],[-40.078125,-29.840644],[-40.078125,29.840644]]\n",
    "# presRange ='[0,500]'\n",
    "# shape = str(atlantic_coords)\n",
    "# URL_PREFIX = 'https://argovis-api.colorado.edu'\n",
    "# startDate = '2021-04-20T00:00:00Z'\n",
    "# endDate   = '2021-05-02T00:00:00Z'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of items: 309\n",
      "https://argovis-api.colorado.edu/profiles?&startDate=2021-04-20T00:00:00Z&endDate=2021-05-02T23:59:59Z&polygon=[[-40.078125, 29.840644], [-33.368671, 30.338837], [-26.614528, 30.492027], [-19.863281, 30.297018], [-20.039063, -30.145127], [-26.724822, -30.384017], [-33.419918, -30.281826], [-40.078125, -29.840644], [-40.078125, 29.840644]]&data=psal,temp,psal_argoqc,pres_argoqc,temp_argoqc&source=argo_core\n"
     ]
    }
   ],
   "source": [
    "# df = get_data_for_timeRange(startDate=startDate,endDate=endDate, \\\n",
    "#                                 url_prefix=URL_PREFIX+'/profiles?', \\\n",
    "#                                 myAPIkey='', \\\n",
    "#                                 source='argo_core', \\\n",
    "#                                 polygon=shape, data='psal,temp,psal_argoqc,pres_argoqc,temp_argoqc', \\\n",
    "#                                 dt_tag='365d',writeFlag=True)\n",
    "\n",
    "# #if we need more variables add to data="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_df(df):\n",
    "    rows = df.shape[0]\n",
    "    master = pd.DataFrame()\n",
    "    for i in range(rows):\n",
    "        profile = pd.DataFrame( df.iloc[i]['data'])\n",
    "        profile['profile_id'] = df.iloc[i]['_id']\n",
    "        master = pd.concat([master, profile])\n",
    "    return master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pres</th>\n",
       "      <th>pres_argoqc</th>\n",
       "      <th>psal</th>\n",
       "      <th>psal_argoqc</th>\n",
       "      <th>temp</th>\n",
       "      <th>temp_argoqc</th>\n",
       "      <th>profile_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.120000</td>\n",
       "      <td>1</td>\n",
       "      <td>37.294998</td>\n",
       "      <td>1.0</td>\n",
       "      <td>26.806999</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3901237_157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.040000</td>\n",
       "      <td>1</td>\n",
       "      <td>37.293999</td>\n",
       "      <td>1.0</td>\n",
       "      <td>26.806</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3901237_157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>37.293999</td>\n",
       "      <td>1.0</td>\n",
       "      <td>26.809</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3901237_157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.960000</td>\n",
       "      <td>1</td>\n",
       "      <td>37.293999</td>\n",
       "      <td>1.0</td>\n",
       "      <td>26.808001</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3901237_157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.960000</td>\n",
       "      <td>1</td>\n",
       "      <td>37.293999</td>\n",
       "      <td>1.0</td>\n",
       "      <td>26.808001</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3901237_157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>1798.649902</td>\n",
       "      <td>1</td>\n",
       "      <td>34.972088</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.989</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5905148_130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>506</th>\n",
       "      <td>1848.250000</td>\n",
       "      <td>1</td>\n",
       "      <td>34.969093</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.897</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5905148_130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>507</th>\n",
       "      <td>1898.549927</td>\n",
       "      <td>1</td>\n",
       "      <td>34.968094</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.821</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5905148_130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>508</th>\n",
       "      <td>1947.949951</td>\n",
       "      <td>1</td>\n",
       "      <td>34.967094</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.738</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5905148_130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>509</th>\n",
       "      <td>1997.449951</td>\n",
       "      <td>1</td>\n",
       "      <td>34.965099</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.668</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5905148_130</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>183485 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            pres  pres_argoqc       psal  psal_argoqc       temp  temp_argoqc  \\\n",
       "0       1.120000            1  37.294998          1.0  26.806999          1.0   \n",
       "1       2.040000            1  37.293999          1.0     26.806          1.0   \n",
       "2       3.000000            1  37.293999          1.0     26.809          1.0   \n",
       "3       3.960000            1  37.293999          1.0  26.808001          1.0   \n",
       "4       4.960000            1  37.293999          1.0  26.808001          1.0   \n",
       "..           ...          ...        ...          ...        ...          ...   \n",
       "505  1798.649902            1  34.972088          1.0      3.989          1.0   \n",
       "506  1848.250000            1  34.969093          1.0      3.897          1.0   \n",
       "507  1898.549927            1  34.968094          1.0      3.821          1.0   \n",
       "508  1947.949951            1  34.967094          1.0      3.738          1.0   \n",
       "509  1997.449951            1  34.965099          1.0      3.668          1.0   \n",
       "\n",
       "      profile_id  \n",
       "0    3901237_157  \n",
       "1    3901237_157  \n",
       "2    3901237_157  \n",
       "3    3901237_157  \n",
       "4    3901237_157  \n",
       "..           ...  \n",
       "505  5905148_130  \n",
       "506  5905148_130  \n",
       "507  5905148_130  \n",
       "508  5905148_130  \n",
       "509  5905148_130  \n",
       "\n",
       "[183485 rows x 7 columns]"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# parse_df(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "presRange ='[0,500]'\n",
    "\n",
    "atlantic_coords = [[-40.078125,29.840644],[-33.368671,30.338837],[-26.614528,30.492027],\n",
    "                [-19.863281,30.297018],[-20.039063,-30.145127],[-26.724822,-30.384017],\n",
    "                [-33.419918,-30.281826],[-40.078125,-29.840644],[-40.078125,29.840644]]\n",
    "\n",
    "shape = str(atlantic_coords)\n",
    "\n",
    "\n",
    "startDate = '2021-04-25T00:00:00Z'\n",
    "endDate   = '2021-05-01T00:00:00Z'\n",
    "\n",
    "\n",
    "\n",
    "def loop_fetch(shape, presRange, date_range):\n",
    "    URL_PREFIX = 'https://argovis-api.colorado.edu'\n",
    "    \n",
    "    df_list = []\n",
    "    \n",
    "    for startDate, endDate in date_range:\n",
    "\n",
    "        df = get_data_for_timeRange(startDate=startDate,endDate=endDate, \\\n",
    "                                        url_prefix=URL_PREFIX+'/profiles?', \\\n",
    "                                        myAPIkey='', \\\n",
    "                                        source='argo_core', \\\n",
    "                                        polygon=shape, data='psal,temp,psal_argoqc,pres_argoqc,temp_argoqc', \\\n",
    "                                        dt_tag='365d',writeFlag=True)\n",
    "        \n",
    "        start_date = startDate.split('T')[0]\n",
    "        \n",
    "        df.to_csv(f'2021_argo_core_dataframe_{start_date}.csv', index=False)\n",
    "        \n",
    "        df_list.append(df)\n",
    "    \n",
    "    \n",
    "    df_all = pd.concat(df_list, ignore_index=True)\n",
    "    \n",
    "    return df_all\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0202e5f95c89be90f20b4128daf1bb0d5a94192fae14c7eccd6f084f465d3275"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
